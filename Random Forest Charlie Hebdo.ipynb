{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03a1e96b-0e99-4d37-8203-8aa59f330d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils import Load_Rumours_Dataset_filtering_since_first_post\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.metrics import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import uuid\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "744ff328-c332-4316-9e8c-2c3d9a35980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "file_path_replies = r\"replies_charlie_hebdo.pkl\"\n",
    "file_path_posts = r\"posts_charlie_hebdo.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc769084-68c9-438b-9f4b-78dc71e8f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Load_Rumours_Dataset_filtering_since_first_post(file_path_replies, file_path_posts, time_cut=3*60*24)\n",
    "processor.load_data()\n",
    "processor.process_data()\n",
    "train,test= processor.get_final_dataframes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccb339d1-276a-4fdb-8489-561e050712c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = train.drop(columns=['rumour'])\n",
    "X_train = np.hstack([X_train.drop(columns=['embeddings_avg']).values, np.array(pd.DataFrame(X_train.embeddings_avg.tolist()))])\n",
    "#X = np.hstack([X.drop(columns=['embeddings_avg']).values, np.array(pd.DataFrame(X.embeddings_avg.tolist()))])\n",
    "y_train =train['rumour']\n",
    "\n",
    "X_test  = test.drop(columns=['rumour'])\n",
    "X_test = np.hstack([X_test.drop(columns=['embeddings_avg']).values, np.array(pd.DataFrame(X_test.embeddings_avg.tolist()))])\n",
    "#X = np.hstack([X.drop(columns=['embeddings_avg']).values, np.array(pd.DataFrame(X.embeddings_avg.tolist()))])\n",
    "y_test =test['rumour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90c9e8b8-cc43-47ca-bcde-49d5bb0c149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights to handle imbalance\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c952f5b-668c-4941-995f-cfe7e041c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights to handle imbalance\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights))\n",
    "\n",
    "# Initialize Random Forest with class weights\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=250,\n",
    "    max_depth=4,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='sqrt',\n",
    "    class_weight=class_weight_dict,  # Handles imbalance\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba_test = model.predict_proba(X_test)[:, 1]  # For ROC AUC\n",
    "\n",
    "y_proba_train = model.predict_proba(X_train)[:, 1]  # For ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91bf9e8e-bb63-498a-9af2-87ebd632b47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Accuracy:  0.8929\n",
      "  - Precision: 0.7309\n",
      "  - Recall:    0.8243\n",
      "  - AUC:       0.9537\n",
      "\n",
      "  - Accuracy:  0.8336\n",
      "  - Precision: 0.6118\n",
      "  - Recall:    0.6940\n",
      "  - AUC:       0.8941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "thresholds = np.linspace(0.01, 0.99, 100)\n",
    "f1_scores = [f1_score(y_train, (y_train_prob > t).astype(int)) for t in thresholds]\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "\n",
    "y_train_pred = (y_train_prob > best_threshold).astype(int)\n",
    "y_test_pred = (y_test_prob > best_threshold).astype(int)\n",
    "\n",
    "thresholds = np.linspace(0.01, 0.99, 100)\n",
    "f1_scores = [f1_score(y_train, (y_train_prob > t).astype(int)) for t in thresholds]\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_threshold\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(y_true, y_pred, y_prob, label=\"\"):\n",
    "    print(f\"  - Accuracy:  {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"  - Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"  - Recall:    {recall_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"  - AUC:       {roc_auc_score(y_true, y_prob):.4f}\")\n",
    "    print(\"\")\n",
    "\n",
    "# Show metrics\n",
    "evaluate(y_train, y_train_pred, y_train_prob, label=\"Train\")\n",
    "evaluate(y_test, y_test_pred, y_test_prob, label=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ededf959-095d-4e2e-9660-b1cb38786e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 12:36:41 INFO mlflow.tracking.fluent: Experiment with name 'Random Forest  2025-06-07 Charlie Hebdo' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/workspaces/rumour-detection-gnn/mlruns/68', creation_time=1749299801922, experiment_id='68', last_update_time=1749299801922, lifecycle_stage='active', name='Random Forest  2025-06-07 Charlie Hebdo', tags={}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "#mlflow.set_experiment(\"spyder-experiment\")\n",
    "import mlflow.pytorch\n",
    "mlflow.set_experiment(\"Random Forest  2025-06-07 Charlie Hebdo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca96dc5-a8b7-41a2-8b9f-64d74771dbd1",
   "metadata": {},
   "source": [
    "#### Testing a Draft model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92b5357-c6b5-4f56-967e-1137e7d3ff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for time_cut in range(20, (60 * 24 * 3), 15):\n",
    "    print(f\"\\n=== Time Cut: {time_cut} ===\")\n",
    "    \n",
    "    processor = Load_Rumours_Dataset_filtering_since_first_post(file_path_replies, file_path_posts, time_cut=time_cut)\n",
    "    processor.load_data()\n",
    "    processor.process_data()\n",
    "    train, test = processor.get_final_dataframes()\n",
    "\n",
    "    # Prepare features and labels\n",
    "    X_train = train.drop(columns=['rumour'])\n",
    "    X_train = np.hstack([\n",
    "        X_train.drop(columns=['embeddings_avg']).values, \n",
    "        np.array(pd.DataFrame(X_train.embeddings_avg.tolist()))\n",
    "    ])\n",
    "    y_train = train['rumour']\n",
    "\n",
    "    X_test = test.drop(columns=['rumour'])\n",
    "    X_test = np.hstack([\n",
    "        X_test.drop(columns=['embeddings_avg']).values, \n",
    "        np.array(pd.DataFrame(X_test.embeddings_avg.tolist()))\n",
    "    ])\n",
    "    y_test = test['rumour']\n",
    "\n",
    "    # Compute class weights to handle imbalance\n",
    "    classes = np.unique(y_train)\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "    class_weight_dict = dict(zip(classes, class_weights))\n",
    "    \n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=50,\n",
    "        max_depth=2,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        max_features='sqrt',\n",
    "        class_weight=class_weight_dict,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"time_cut_{time_cut}\"):\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Probabilities\n",
    "        y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "        y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Find best threshold to maximize F1 on train set\n",
    "        thresholds = np.linspace(0.01, 0.99, 100)\n",
    "        f1_scores = [f1_score(y_train, (y_train_prob > t).astype(int)) for t in thresholds]\n",
    "        best_idx = np.argmax(f1_scores)\n",
    "        best_threshold = thresholds[best_idx]\n",
    "\n",
    "        # Apply best threshold\n",
    "        y_train_pred = (y_train_prob > best_threshold).astype(int)\n",
    "        y_test_pred = (y_test_prob > best_threshold).astype(int)\n",
    "\n",
    "        # Train metrics\n",
    "        mlflow.log_metric(\"train_accuracy\", accuracy_score(y_train, y_train_pred))\n",
    "        mlflow.log_metric(\"train_precision\", precision_score(y_train, y_train_pred))\n",
    "        mlflow.log_metric(\"train_recall\", recall_score(y_train, y_train_pred))\n",
    "        mlflow.log_metric(\"train_f1\", f1_score(y_train, y_train_pred))\n",
    "        mlflow.log_metric(\"train_auc\", roc_auc_score(y_train, y_train_prob))\n",
    "\n",
    "        # Test metrics\n",
    "        mlflow.log_metric(\"final_acc\", accuracy_score(y_test, y_test_pred))\n",
    "        mlflow.log_metric(\"final_precision\", precision_score(y_test, y_test_pred))\n",
    "        mlflow.log_metric(\"final_recall\", recall_score(y_test, y_test_pred))\n",
    "        mlflow.log_metric(\"final_f1\", f1_score(y_test, y_test_pred))\n",
    "        mlflow.log_metric(\"final_auc\", roc_auc_score(y_test, y_test_prob))\n",
    "\n",
    "        # Log best threshold and time_cut\n",
    "        mlflow.log_metric(\"optimal_threshold\", best_threshold)\n",
    "        mlflow.log_metric(\"time_cut\", time_cut)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
