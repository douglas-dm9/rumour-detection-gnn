{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83c689f3-10a3-46d5-9c4d-a89cd263d964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tdqm in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.0.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tdqm) (4.66.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install tdqm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a32e5865-d8ab-4881-ba1c-ad8490084659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /usr/local/python/3.10.13/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in /usr/local/python/3.10.13/lib/python3.10/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from xgboost) (2.22.3)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from xgboost) (1.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "832a8576-cc04-42ce-a2e3-e933305ded20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,accuracy_score,recall_score,precision_score\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "from utils import LoadRumoursDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5134e825-a668-4284-8e01-5ff2e29930be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/17 13:04:45 INFO mlflow.tracking.fluent: Experiment with name 'ML Models 2024-08-17' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/workspaces/rumour-detection-pheme/mlruns/6', creation_time=1723899885838, experiment_id='6', last_update_time=1723899885838, lifecycle_stage='active', name='ML Models 2024-08-17', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "#mlflow.set_experiment(\"spyder-experiment\")\n",
    "import mlflow.pytorch\n",
    "mlflow.set_experiment(\"ML Models 2024-08-17\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "721832e6-7c71-4657-ba3f-36aac7991cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "file_path_replies = r\"/workspaces/rumour-detection-pheme/replies_charlie_hebdo.pkl\"\n",
    "file_path_posts = r\"/workspaces/rumour-detection-pheme/posts_charlie_hebdo.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "500e374e-1d13-479c-9aea-b1f6a8aece2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cut =1e6\n",
    "processor = LoadRumoursDataset(file_path_replies, file_path_posts, time_cut)\n",
    "processor.load_data()\n",
    "processor.process_data()\n",
    "df_final = processor.get_final_dataframe()\n",
    "\n",
    "X  = df_final.drop(columns=['rumour'])\n",
    "X = np.hstack([X.drop(columns=['embeddings_avg']).values, np.array(pd.DataFrame(X.embeddings_avg.tolist()))])\n",
    "y =df_final['rumour']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42,stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5e3e0d6-5dda-48f8-9542-ddc4f3de669b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>followers</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>rumour</th>\n",
       "      <th>embeddings_avg</th>\n",
       "      <th>replies</th>\n",
       "      <th>first_time_diff</th>\n",
       "      <th>no_verified</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.073004</td>\n",
       "      <td>-0.532290</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.12270056130364537, 0.01583862374536693, -0...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.510619</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031065</td>\n",
       "      <td>-0.344423</td>\n",
       "      <td>1.293333</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.12335950043052435, -0.055849663292368255, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999077</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.356672</td>\n",
       "      <td>-0.524462</td>\n",
       "      <td>-0.302222</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.1364929385483265, -0.07159566258390744, -0...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.740536</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.332156</td>\n",
       "      <td>-0.524462</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.045377860377941816, -0.20127306692302227, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.164358</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.046022</td>\n",
       "      <td>-0.391389</td>\n",
       "      <td>0.964444</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.03706469060853124, -0.1309182441327721, -0...</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.352724</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>3.895910</td>\n",
       "      <td>-0.140900</td>\n",
       "      <td>-0.124444</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.21622000262141228, -0.15450449846684933, -0...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.204986</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>10.452911</td>\n",
       "      <td>3.859100</td>\n",
       "      <td>5.213333</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.21485890651291067, 0.03315381561829285, -0....</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.245614</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.012322</td>\n",
       "      <td>1.189824</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.08846200071275234, -0.1485882457345724, 0.1...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.500462</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>3.631498</td>\n",
       "      <td>0.477495</td>\n",
       "      <td>1.075556</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.021962551607025996, -0.019428667094972398, ...</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.271468</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>0.952113</td>\n",
       "      <td>-0.320939</td>\n",
       "      <td>-0.275556</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.11712110787630081, -0.1469299958811866, -0....</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.049861</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2002 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      followers  favorite_count  retweet_count  rumour  \\\n",
       "0     -0.073004       -0.532290      -0.160000       1   \n",
       "1      0.031065       -0.344423       1.293333       1   \n",
       "2      0.356672       -0.524462      -0.302222       1   \n",
       "3      0.332156       -0.524462      -0.400000       1   \n",
       "4      1.046022       -0.391389       0.964444       1   \n",
       "...         ...             ...            ...     ...   \n",
       "1997   3.895910       -0.140900      -0.124444       0   \n",
       "1998  10.452911        3.859100       5.213333       0   \n",
       "1999   0.012322        1.189824       0.955556       0   \n",
       "2000   3.631498        0.477495       1.075556       0   \n",
       "2001   0.952113       -0.320939      -0.275556       0   \n",
       "\n",
       "                                         embeddings_avg  replies  \\\n",
       "0     [-0.12270056130364537, 0.01583862374536693, -0...        5   \n",
       "1     [-0.12335950043052435, -0.055849663292368255, ...        5   \n",
       "2     [-0.1364929385483265, -0.07159566258390744, -0...        5   \n",
       "3     [-0.045377860377941816, -0.20127306692302227, ...        3   \n",
       "4     [-0.03706469060853124, -0.1309182441327721, -0...       10   \n",
       "...                                                 ...      ...   \n",
       "1997  [0.21622000262141228, -0.15450449846684933, -0...        8   \n",
       "1998  [0.21485890651291067, 0.03315381561829285, -0....        9   \n",
       "1999  [0.08846200071275234, -0.1485882457345724, 0.1...        9   \n",
       "2000  [0.021962551607025996, -0.019428667094972398, ...       18   \n",
       "2001  [0.11712110787630081, -0.1469299958811866, -0....        5   \n",
       "\n",
       "      first_time_diff  no_verified  verified  \n",
       "0            3.510619            1         0  \n",
       "1            0.999077            0         1  \n",
       "2            0.740536            0         1  \n",
       "3           -0.164358            0         1  \n",
       "4           -0.352724            0         1  \n",
       "...               ...          ...       ...  \n",
       "1997         0.204986            0         1  \n",
       "1998        -0.245614            0         1  \n",
       "1999         0.500462            1         0  \n",
       "2000        -0.271468            0         1  \n",
       "2001        -0.049861            0         1  \n",
       "\n",
       "[2002 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff08c3f5-cf3b-4138-8955-2913e01a668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_log_curves(history, metric_name, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history['train'], label='Training')\n",
    "    plt.plot(history['val'], label='Validation')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'{metric_name}_curve.png')\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(f'{metric_name}_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eda11819-925d-4ad0-ae6e-31e6fa286f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def train_optimize_model_with_mlflow(model, param_grid, cv, scoring, X_train, y_train, X_test, y_test,time_cut):\n",
    "    \"\"\"\n",
    "    Train a Gradient Boosting Classifier with GridSearchCV and log the results with MLflow.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The machine learning model (e.g., GradientBoostingClassifier()).\n",
    "    - param_grid: The grid of parameters to search over.\n",
    "    - cv: The cross-validation strategy (e.g., 5 for 5-fold cross-validation).\n",
    "    - scoring: The scoring method for model evaluation (e.g., 'f1').\n",
    "    - X_train: Training data features.\n",
    "    - y_train: Training data labels.\n",
    "    - X_test: Test data features.\n",
    "    - y_test: Test data labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Setup the grid search\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, scoring=scoring, verbose=2, n_jobs=2)\n",
    "\n",
    "    # Start an MLflow run\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        # Set the tag with the model name\n",
    "        mlflow.set_tag(\"model_name\", model.__class__.__name__)\n",
    "        \n",
    "        # Perform the grid search\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Get the best parameters\n",
    "        best_params = grid_search.best_params_\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "        # Train the best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        y_train_pred = best_model.predict(X_train)\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        metrics = {\n",
    "            \"train_recall\": recall_score(y_train, y_train_pred, average='macro'),\n",
    "            \"train_precision\": precision_score(y_train, y_train_pred, average='macro'),\n",
    "            \"train_f1_score\": f1_score(y_train, y_train_pred, average='macro'),\n",
    "            \"train_accuracy\": accuracy_score(y_train, y_train_pred),\n",
    "            \"test_recall\": recall_score(y_test, y_test_pred, average='macro'),\n",
    "            \"test_precision\": precision_score(y_test, y_test_pred, average='macro'),\n",
    "            \"test_f1_score\": f1_score(y_test, y_test_pred, average='macro'),\n",
    "            \"test_accuracy\": accuracy_score(y_test, y_test_pred)\n",
    "        }\n",
    "\n",
    "        # Log parameters and metrics\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_param(\"time_cut\",time_cut)\n",
    "        mlflow.log_metrics(metrics)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(best_model, \"model\")\n",
    "        \n",
    "        print(\"best params: \\n\",best_params)\n",
    "        print(\"Metrics: \\n\",metrics)\n",
    "\n",
    "        return best_params\n",
    "\n",
    "    # End the MLflow run (this happens automatically when the 'with' block ends)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7c5b59-60fd-4111-b77e-f933cdbb7fb3",
   "metadata": {},
   "source": [
    "#### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10d9d213-5edd-4528-885a-3af5253816d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best parameters: {'learning_rate': 0.1, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "2024/08/17 13:13:17 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: \n",
      " {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Metrics: \n",
      " {'train_recall': 0.9957983193277311, 'train_precision': 0.9987971130713713, 'train_f1_score': 0.9972881275545551, 'train_accuracy': 0.9981261711430356, 'test_recall': 0.8042515183994283, 'test_precision': 0.8117358518193133, 'test_f1_score': 0.8078824858757062, 'test_accuracy': 0.8678304239401496}\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.001, 0.01,0.1],\n",
    "    'max_depth': [3, 10,15],\n",
    "    #'subsample': [0.7, 0.8],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "cv = 5 \n",
    "scoring = 'f1'\n",
    "\n",
    "best_params =train_optimize_model_with_mlflow(gbc, param_grid, cv, scoring, X_train, y_train, X_test, y_test,time_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ecabe64-db24-446b-bc43-3fda96448bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............learning_rate=0.001, n_estimators=100; total time=   4.8s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=100; total time=   4.4s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=200; total time=   9.2s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=200; total time=   9.1s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=200; total time=   9.3s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   4.6s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   4.6s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=   9.1s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=   9.2s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   4.8s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   4.7s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   4.7s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=   9.4s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=   9.2s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=   8.2s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=100; total time=   4.5s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=100; total time=   4.6s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=100; total time=   4.5s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=200; total time=   9.1s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=200; total time=   9.2s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   4.7s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   4.5s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   4.4s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=   9.2s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=   9.3s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=   9.1s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   4.7s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   4.7s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=   9.3s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=   9.3s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=100; total time=   4.6s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=100; total time=   4.4s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=100; total time=   4.4s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=200; total time=   9.2s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=200; total time=   9.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   4.7s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   4.5s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   4.6s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=   9.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=   9.3s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=   9.2s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   4.8s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   4.6s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=   9.3s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=   9.3s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=100; total time=   4.5s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=100; total time=   4.6s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=200; total time=   9.3s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=200; total time=   9.1s\n",
      "[CV] END ..............learning_rate=0.001, n_estimators=200; total time=   9.2s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   4.6s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time=   4.5s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=   9.2s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time=   9.1s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   4.6s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   4.5s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=100; total time=   4.8s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=   9.4s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=   9.2s\n",
      "[CV] END ................learning_rate=0.1, n_estimators=200; total time=   8.3s\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "def train_and_log_model(model, best_params, X_train, y_train, X_test, y_test, time_cut):\n",
    "    # Define the model\n",
    "    \n",
    "    # Set the best parameters\n",
    "    model.set_params(**best_params)\n",
    "    \n",
    "    # Start an MLflow run\n",
    "    with mlflow.start_run():\n",
    "        # Set the tag with the model name\n",
    "        mlflow.set_tag(\"model_name\", model.__class__.__name__)\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        metrics = {\n",
    "            \"train_recall\": recall_score(y_train, y_train_pred, average='macro'),\n",
    "            \"train_precision\": precision_score(y_train, y_train_pred, average='macro'),\n",
    "            \"train_f1_score\": f1_score(y_train, y_train_pred, average='macro'),\n",
    "            \"train_accuracy\": accuracy_score(y_train, y_train_pred),\n",
    "            \"test_recall\": recall_score(y_test, y_test_pred, average='macro'),\n",
    "            \"test_precision\": precision_score(y_test, y_test_pred, average='macro'),\n",
    "            \"test_f1_score\": f1_score(y_test, y_test_pred, average='macro'),\n",
    "            \"test_accuracy\": accuracy_score(y_test, y_test_pred)\n",
    "        }\n",
    "\n",
    "        # Log parameters and metrics\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        mlflow.log_param(\"time_cut\", time_cut)\n",
    "\n",
    "        # Log the model with example input\n",
    "        example_input = np.array(X_train[0]).reshape(1, -1)  # Use the shape of your feature set\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, \"model\", input_example=example_input)\n",
    "\n",
    "        print(\"Metrics: \\n\", metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "016d76a8-bc92-4f2d-a911-7be828894324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac5831a791746b388f2ac75310a7c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: \n",
      " {'train_recall': 0.5, 'train_precision': 0.3885071830106184, 'train_f1_score': 0.4372583479789104, 'train_accuracy': 0.7770143660212367, 'test_recall': 0.5, 'test_precision': 0.3877805486284289, 'test_f1_score': 0.43679775280898875, 'test_accuracy': 0.7755610972568578}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage:\n",
    "\n",
    "# Define the model\n",
    "model = GradientBoostingClassifier()\n",
    "time_cut =1e6\n",
    "\n",
    "train_and_log_model(model,best_params, X_train, y_train, X_test, y_test,time_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed7d692-f42a-4b2c-aa42-e89e49a6effa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8f5547-5262-4503-815f-b6c2ae2e4a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67675f03-194e-417c-a075-d874a898c75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59978ecc-84f0-4b71-aedc-9ef0e5dbf53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeaf977-a641-4238-9225-ba57b94ba0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81413c7-5d6a-4cf8-9872-c04532765e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfab0a0-325f-41d7-be0d-aaa0b1bfff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Gradient Boosting classifier\n",
    "gb_classifier = GradientBoostingClassifier(**best_params)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "gb_pred = gb_classifier.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "gb_precision = precision_score(y_test, gb_pred, average='macro')\n",
    "gb_recall = recall_score(y_test, gb_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0351114-f72e-48d4-b7e7-5dddc5aef1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GB Accuracy:\", gb_accuracy)\n",
    "print(\"GB Precision:\", gb_precision)\n",
    "print(\"GB Recall:\", gb_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c96d10b-64fa-4874-9742-2c6e5ada14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb = XGBClassifier(eval_metric='logloss')\n",
    "\n",
    "# Train the best model\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_pred)\n",
    "xgb_precision = precision_score(y_test, xgb_pred, average='macro')\n",
    "xgb_recall = recall_score(y_test, xgb_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03479a8b-08c2-4193-b743-9261b3bf038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Accuracy: 0.8653366583541147\n",
      "XGB Precision: 0.8111667558681857\n",
      "XGB Recall: 0.790800285816363\n"
     ]
    }
   ],
   "source": [
    "print(\"XGB Accuracy:\", xgb_accuracy)\n",
    "print(\"XGB Precision:\", xgb_precision)\n",
    "print(\"XGB Recall:\", xgb_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b443e-7ca1-4814-8a77-3f2a9a2e33e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress: 100%|█████████████████████████████| 5/5 [00:00<00:00, 2305.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.9; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.9; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.9; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.9; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.9; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.9; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.7s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.7; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.7; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.7; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.9; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.9; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.9; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=1.0; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=1.0; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.7; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.7; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.7; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9; total time=   1.7s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9; total time=   1.7s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.7; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.7; total time=   3.0s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.7; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9; total time=   3.4s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9; total time=   3.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.7; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.9; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.9; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.7; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.7; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.9; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.9; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.7; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.7s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.7s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.7s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   2.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.7; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.7; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.8; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.9; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.9; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=1.0; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=1.0; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=50, subsample=1.0; total time=   0.9s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.7; total time=   1.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.7; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.7; total time=   2.9s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.7; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.2s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.3s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9; total time=   3.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9; total time=   3.2s\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "xgb = XGBClassifier(eval_metric='logloss')\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0]\n",
    "    #'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "    #'min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Create a StratifiedKFold object with tqdm progress bar\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "cv_splits = list(cv.split(X_train, y_train))\n",
    "tqdm_cv_splits = tqdm(cv_splits, total=len(cv_splits), desc=\"Grid Search Progress\")\n",
    "\n",
    "# Setup the grid search with the tqdm progress bar\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=tqdm_cv_splits, scoring='f1', verbose=2, n_jobs=-1)\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Train the best model\n",
    "best_xgb = grid_search.best_estimator_\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52004bd7-7e4e-4179-bace-ae7c3bb6dd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f58d5381-9ad0-4802-aaee-c693f100b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
