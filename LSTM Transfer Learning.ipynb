{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adceab28-8144-40e4-a054-38f843cfed88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import *\n",
    "from tqdm import tqdm\n",
    "from utils import Load_Rumours_Dataset_filtering_since_first_post_Transfer_Learning\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "459baa4a-bebe-4d5e-b4d8-703538b97f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rumour\n",
      "0    535\n",
      "1    286\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_dataset = 'charlie_hebdo'\n",
    "test_dataset = 'sydneysiege'\n",
    "time_cut =3*60*24\n",
    "processor = Load_Rumours_Dataset_filtering_since_first_post_Transfer_Learning(train_dataset,\\\n",
    "           test_dataset, time_cut=time_cut,test_size=0.7)\n",
    "\n",
    "processor.load_data()\n",
    "processor.process_data()\n",
    "train,test = processor.get_final_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "551f7876-9528-433d-88db-019436584338",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = train.drop(columns=['rumour'])\n",
    "X_train = np.hstack([X_train.drop(columns=['embeddings_avg']).values, np.array(pd.DataFrame(X_train.embeddings_avg.tolist()))])\n",
    "\n",
    "\n",
    "X_test  = test.drop(columns=['rumour'])\n",
    "X_test = np.hstack([X_test.drop(columns=['embeddings_avg']).values, np.array(pd.DataFrame(X_test.embeddings_avg.tolist()))])\n",
    "\n",
    "#X = np.hstack([X.drop(columns=['embeddings_avg']).values, np.array(pd.DataFrame(X.embeddings_avg.tolist()))])\n",
    "y_train =train['rumour']\n",
    "y_test =test['rumour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4d6eced-29ad-4a84-928b-18db0f0b6eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "\n",
    "# Model definition\n",
    "class RumorDetectionLSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim=100, lstm_hidden_size=32, dense_hidden_size=16):\n",
    "        super(RumorDetectionLSTM, self).__init__()\n",
    "        \n",
    "        # LSTM for the 100-dimensional embeddings\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=lstm_hidden_size, batch_first=True)\n",
    "        \n",
    "        # Dense layers for other features\n",
    "        self.dense1 = nn.Linear(8, 16)  # 8 non-embedding features\n",
    "        self.dense2 = nn.Linear(16, dense_hidden_size)\n",
    "        \n",
    "        # Combine LSTM and dense features\n",
    "        self.fc1 = nn.Linear(lstm_hidden_size + dense_hidden_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Separate embeddings and other features\n",
    "        embeddings = x[:, -100:].unsqueeze(1)  # (batch, seq_len=1, embedding_dim)\n",
    "        other_features = x[:, :8]  # First 8 features\n",
    "        \n",
    "        # LSTM output\n",
    "        lstm_out, _ = self.lstm(embeddings)\n",
    "        lstm_out = lstm_out[:, -1, :]  # Get the last LSTM output\n",
    "        \n",
    "        # Dense layers for other features\n",
    "        dense_out = torch.relu(self.dense1(other_features))\n",
    "        dense_out = torch.relu(self.dense2(dense_out))\n",
    "        \n",
    "        # Concatenate LSTM and dense outputs\n",
    "        combined = torch.cat((lstm_out, dense_out), dim=1)\n",
    "        \n",
    "        # Fully connected layers for classification\n",
    "        x = torch.relu(self.fc1(combined))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea857a87-d398-40db-8550-efc6f1303a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train, X_test, y_train, and y_test are available as numpy arrays\n",
    "# Convert them to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Dataset and DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "461e799f-3dc3-4bbb-846f-d0640938bdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, Train Loss: 19.0257,              Train Precision: 1.0000,Train Recall: 0.3227\n",
      "Final Test Recall: 0.4650\n",
      "Final Test Precision: 0.6856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "# Model, criterion, optimizer initialization (as before)\n",
    "model = RumorDetectionLSTM()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop with loss and recall monitoring\n",
    "epochs = 75  # Adjust as needed\n",
    "train_recall_interval = 50  # Calculate train recall every 10 epochs\n",
    "loss_interval = 50  # Print loss every 10 epochs\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Print loss every 10 epochs\n",
    "    if (epoch + 1) % loss_interval == 0:\n",
    "        model.eval()\n",
    "        train_preds = []\n",
    "        train_labels = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                output = model(X_batch)\n",
    "                preds = (output >= 0.5).int()  # Binarize predictions\n",
    "                train_preds.extend(preds.tolist())\n",
    "                train_labels.extend(y_batch.tolist())\n",
    "        \n",
    "        train_recall = recall_score(train_labels, train_preds)\n",
    "        train_precision = precision_score(train_labels, train_preds)\n",
    "        \n",
    "print(f\"Epoch {epoch + 1}, Train Loss: {epoch_loss / len(train_loader):.4f},\\\n",
    "              Train Precision: {train_precision:.4f},Train Recall: {train_recall:.4f}\")\n",
    "    \n",
    "\n",
    "\n",
    "# Final evaluation on test set with recall and precision\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        output = model(X_batch)\n",
    "        preds = (output >= 0.5).int()  # Binarize predictions\n",
    "        test_preds.extend(preds.tolist())\n",
    "        test_labels.extend(y_batch.tolist())\n",
    "\n",
    "# Calculate final test recall and precision\n",
    "test_recall = recall_score(test_labels, test_preds)\n",
    "test_precision = precision_score(test_labels, test_preds)\n",
    "\n",
    "print(f\"Final Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Final Test Precision: {test_precision:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "356b65e6-749c-4cd1-bf3a-d4162ebe2cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/workspaces/rumour-detection-gnn/mlruns/103', creation_time=1752687500205, experiment_id='103', last_update_time=1752687500205, lifecycle_stage='active', name='LSTM  2025-07-15 Ottawa Shooting', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "#mlflow.set_experiment(\"spyder-experiment\")\n",
    "import mlflow.pytorch\n",
    "mlflow.set_experiment(\"LSTM  2025-07-15 Ottawa Shooting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbc01db-e119-40c7-8436-64967e195c8d",
   "metadata": {},
   "source": [
    "#### Testing Draf Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058d7004-3992-4a08-9fd0-cf9b3a65e8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "def find_best_f1_threshold(y_true, y_probs):\n",
    "    thresholds = np.linspace(0.05, 1, 20)\n",
    "    best_thresh = 0.5\n",
    "    best_f1 = 0\n",
    "    for thresh in thresholds:\n",
    "        preds = (y_probs >= thresh).astype(int)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, preds, average=\"binary\")\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thresh = thresh\n",
    "    return best_thresh\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            output = model(X_batch).squeeze()\n",
    "            all_logits.extend(output.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "    probs = torch.sigmoid(torch.tensor(all_logits)).numpy()\n",
    "    labels = np.array(all_labels)\n",
    "    auc = roc_auc_score(labels, probs)\n",
    "    return labels, probs, auc\n",
    "\n",
    "for time_cut in range(10, 24*3*60, 15):\n",
    "    print(time_cut)\n",
    "    \n",
    "    train_dataset = 'charlie_hebdo'\n",
    "    test_dataset = 'ottawa_shooting'\n",
    "    processor = Load_Rumours_Dataset_filtering_since_first_post_Transfer_Learning(train_dataset, test_dataset, time_cut=time_cut, test_size=0.7)\n",
    "    \n",
    "    processor.load_data()\n",
    "    processor.process_data()\n",
    "    train, test = processor.get_final_dataframes()\n",
    "\n",
    "    X_train = train.drop(columns=['rumour'])\n",
    "    X_train = np.hstack([X_train.drop(columns=['embeddings_avg']).values, np.array(pd.DataFrame(X_train.embeddings_avg.tolist()))])\n",
    "\n",
    "    X_test = test.drop(columns=['rumour'])\n",
    "    X_test = np.hstack([X_test.drop(columns=['embeddings_avg']).values, np.array(pd.DataFrame(X_test.embeddings_avg.tolist()))])\n",
    "\n",
    "    y_train = train['rumour']\n",
    "    y_test = test['rumour']\n",
    "\n",
    "    #smote = SMOTE(random_state=42, sampling_strategy='minority')\n",
    "    #X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "    # Handle class imbalance\n",
    "    num_pos = sum(y_train)\n",
    "    num_neg = len(y_train) - num_pos\n",
    "    pos_weight = torch.tensor([num_neg / num_pos], dtype=torch.float32)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        model = RumorDetectionLSTM()\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        epochs = 200\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                output = model(X_batch).squeeze()\n",
    "                loss = criterion(output, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Evaluate at every epoch\n",
    "            y_train_true, y_train_probs, auc_train = evaluate(model, train_loader)\n",
    "            y_test_true, y_test_probs, auc_test = evaluate(model, test_loader)\n",
    "\n",
    "            best_thresh = find_best_f1_threshold(y_train_true, y_train_probs)\n",
    "\n",
    "        def compute_metrics(y_true, y_probs, threshold):\n",
    "            preds = (y_probs >= threshold).astype(int)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(y_true, preds, average='binary')\n",
    "            return precision, recall, f1\n",
    "\n",
    "        best_thresh = find_best_f1_threshold(y_train_true, y_train_probs)\n",
    "\n",
    "        prec_train, rec_train, f1_train = compute_metrics(y_train_true, y_train_probs, best_thresh)\n",
    "        prec_test, rec_test, f1_test = compute_metrics(y_test_true, y_test_probs, best_thresh)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        print(f\"  Train AUC: {auc_train:.4f} | Precision: {prec_train:.4f} | Recall: {rec_train:.4f} | F1: {f1_train:.4f}\")\n",
    "        print(f\"  Test  AUC: {auc_test:.4f} | Precision: {prec_test:.4f} | Recall: {rec_test:.4f} | F1: {f1_test:.4f}\")\n",
    "        print(f\"  Threshold: {best_thresh:.2f}\\n\")\n",
    "\n",
    "        # Log final test results\n",
    "        mlflow.log_metric(\"final_test_precision\", prec_test)\n",
    "        mlflow.log_metric(\"final_test_recall\", rec_test)\n",
    "        mlflow.log_metric(\"final_test_f1\", f1_test)\n",
    "        mlflow.log_metric(\"final_test_auc\", auc_test)\n",
    "        mlflow.log_param(\"best_threshold\", best_thresh)\n",
    "        mlflow.log_param(\"learning_rate\", 0.001)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"time_cut\", time_cut)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
