{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec2cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9df83fc-2853-428d-9e7c-6633bd8ddf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadRumoursDataset:\n",
    "    def __init__(self, file_path_replies, file_path_posts, time_cut):\n",
    "        self.file_path_replies = file_path_replies\n",
    "        self.file_path_posts = file_path_posts\n",
    "        self.time_cut = time_cut\n",
    "        self.df_replies = None\n",
    "        self.df_posts = None\n",
    "        self.df_final = None\n",
    "\n",
    "    def load_data(self):\n",
    "        self.df_replies = pd.read_pickle(self.file_path_replies)\n",
    "        self.df_posts = pd.read_pickle(self.file_path_posts)\n",
    "\n",
    "    def process_data(self):\n",
    "        post_features = ['followers','favorite_count','retweet_count','verified','rumour','id','embeddings_avg']\n",
    "        reply_features = ['reply_followers','reply_user_id','reply_verified','time_diff','reply_embeddings_avg','id']\n",
    "\n",
    "        filtered_replies = self.df_replies[reply_features][self.df_replies.time_diff < self.time_cut]\n",
    "        grouped_replies = filtered_replies.groupby(['id']).agg(\n",
    "            replies=('time_diff', 'count'),\n",
    "            first_time_diff=('time_diff', 'first')\n",
    "        ).reset_index()\n",
    "\n",
    "        self.df_posts = self.df_posts[post_features]\n",
    "        self.df_final = self.df_posts.merge(grouped_replies, on=\"id\", how=\"left\")\n",
    "        self.df_final['replies'] = self.df_final['replies'].fillna(0)\n",
    "        self.df_final['first_time_diff'] = self.df_final['first_time_diff'].fillna(0)\n",
    "        self.df_final = self.df_final.drop(columns=['id'])\n",
    "\n",
    "        # One-hot encoding\n",
    "        self.df_final ['verified'] = self.df_final ['verified'].astype('str').str.\\\n",
    "                     replace(' ', '').replace('True', '1').replace('False', '0')\\\n",
    "                     .astype('int64')\n",
    "        \n",
    "        self.df_final  = pd.concat([self.df_final , pd.get_dummies(\\\n",
    "                                  self.df_final [\"verified\"],dtype=int)], axis=1, join='inner')\n",
    "        self.df_final .drop([\"verified\"], axis=1, inplace=True)\n",
    "        self.df_final .rename(columns={1:'verified',0:'no_verified'},inplace=True)\n",
    "\n",
    "    def get_final_dataframe(self):\n",
    "        return self.df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6308c8a-a7f3-4f8a-8eac-9964ad649b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroDataProcessor:\n",
    "    def __init__(self, file_path_replies, file_path_posts, time_cut=15):\n",
    "        self.file_path_replies = file_path_replies\n",
    "        self.file_path_posts = file_path_posts\n",
    "        self.time_cut = time_cut\n",
    "        self.df_replies = None\n",
    "        self.df_posts = None\n",
    "        self.post_map = None\n",
    "        self.reply_user_map = None\n",
    "\n",
    "    def load_data(self):\n",
    "        self.df_replies = pd.read_pickle(self.file_path_replies)\n",
    "        self.df_posts = pd.read_pickle(self.file_path_posts)\n",
    "\n",
    "    def process_data(self):\n",
    "        post_features = ['followers', 'favorite_count', 'retweet_count', 'verified', 'rumour', 'id', 'embeddings_avg']\n",
    "        reply_features = ['reply_followers', 'reply_user_id', 'reply_verified', 'time_diff', 'reply_embeddings_avg', 'id']\n",
    "\n",
    "        # Filter and group replies\n",
    "        self.df_replies = self.df_replies[reply_features][self.df_replies.time_diff < self.time_cut]\n",
    "        grouped_replies = self.df_replies.groupby(['id']).agg(\n",
    "            replies=('time_diff', 'count'),\n",
    "            first_time_diff=('time_diff', 'first')\n",
    "        ).reset_index()\n",
    "\n",
    "        # Merge posts and replies\n",
    "        self.df_posts = self.df_posts[post_features].merge(grouped_replies, on=\"id\", how=\"left\")\n",
    "        self.df_posts['replies'] = self.df_posts['replies'].fillna(0)\n",
    "        self.df_posts['first_time_diff'] = self.df_posts['first_time_diff'].fillna(0)\n",
    "\n",
    "        # One-hot encoding for verified columns\n",
    "        self.df_posts['verified'] = self.df_posts['verified'].astype(str).replace({'True': '1', 'False': '0'}).astype(int)\n",
    "        self.df_posts = pd.concat([self.df_posts, pd.get_dummies(self.df_posts[\"verified\"], dtype=int)], axis=1)\n",
    "        self.df_posts.drop([\"verified\"], axis=1, inplace=True)\n",
    "        self.df_posts.rename(columns={1: 'verified', 0: 'no_verified'}, inplace=True)\n",
    "\n",
    "        self.df_replies['reply_verified'] = self.df_replies['reply_verified'].astype(str).replace({'True': '1', 'False': '0'}).astype(int)\n",
    "        self.df_replies = pd.concat([self.df_replies, pd.get_dummies(self.df_replies[\"reply_verified\"], dtype=int)], axis=1)\n",
    "        self.df_replies.drop([\"reply_verified\"], axis=1, inplace=True)\n",
    "        self.df_replies.rename(columns={1: 'reply_verified', 0: 'reply_no_verified'}, inplace=True)\n",
    "\n",
    "        # Mapping post ids\n",
    "        self.post_map = {value: i for i, value in enumerate(self.df_posts['id'].unique())}\n",
    "        self.df_replies[\"id\"] = self.df_replies['id'].map(self.post_map).astype(int)\n",
    "\n",
    "        # Mapping reply user ids\n",
    "        self.reply_user_map = {value: i for i, value in enumerate(self.df_replies['reply_user_id'].unique())}\n",
    "        self.df_replies[\"reply_user_id\"] = self.df_replies[\"reply_user_id\"].map(self.reply_user_map).astype(int)\n",
    "\n",
    "    def create_features(self):\n",
    "        post_features = self.df_posts[[\"followers\", \"favorite_count\", \"retweet_count\", \"no_verified\", \"verified\", \"first_time_diff\"]]\n",
    "        post_embeddings = np.array(self.df_posts['embeddings_avg'].tolist())\n",
    "        #post_features = self.scaler.fit_transform(post_features)\n",
    "        x1 = np.concatenate((post_features, post_embeddings), axis=1)\n",
    "\n",
    "        reply_features = self.df_replies[[\"reply_followers\", \"reply_no_verified\", \"reply_verified\", \"time_diff\"]]\n",
    "        reply_embeddings = np.array(self.df_replies['reply_embeddings_avg'].tolist())\n",
    "        #reply_features = self.scaler.transform(reply_features)\n",
    "        x2 = np.concatenate((reply_features, reply_embeddings), axis=1)\n",
    "\n",
    "        return x1, x2\n",
    "\n",
    "    def create_heterodata(self, x1, x2):\n",
    "        y = self.df_posts['rumour'].to_numpy()\n",
    "        edge_index = self.df_replies[[\"id\", \"reply_user_id\"]].values.T\n",
    "\n",
    "        num_rows = x1.shape[0]\n",
    "        indices = np.arange(num_rows)\n",
    "        np.random.shuffle(indices)\n",
    "        train_end = int(0.70 * num_rows)\n",
    "        val_end = train_end + int(0.15 * num_rows)\n",
    "        train_indices, val_indices, test_indices = indices[:train_end], indices[train_end:val_end], indices[val_end:]\n",
    "\n",
    "        train_mask = np.zeros(num_rows, dtype=bool)\n",
    "        val_mask = np.zeros(num_rows, dtype=bool)\n",
    "        test_mask = np.zeros(num_rows, dtype=bool)\n",
    "        train_mask[train_indices], val_mask[val_indices], test_mask[test_indices] = True, True, True\n",
    "\n",
    "        data = HeteroData()\n",
    "        data['user_id'].x = torch.tensor(x1, dtype=torch.float32)\n",
    "        data['user_id'].y = torch.tensor(y, dtype=torch.float32)\n",
    "        data['user_id'].train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
    "        data['user_id'].val_mask = torch.tensor(val_mask, dtype=torch.bool)\n",
    "        data['user_id'].test_mask = torch.tensor(test_mask, dtype=torch.bool)\n",
    "        data['reply_id'].x = torch.tensor(x2, dtype=torch.float32)\n",
    "        data['user_id', 'retweet', 'reply_id'].edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "        data = T.ToUndirected()(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def process(self):\n",
    "        self.load_data()\n",
    "        self.process_data()\n",
    "        x1, x2 = self.create_features()\n",
    "        return self.create_heterodata(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab31227a-b2c0-47e2-aad4-87f6974c90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "file_path_replies = r\"/workspaces/rumour-detection-pheme/Dataset creation/replies_charlie_hebdo.pkl\"\n",
    "file_path_posts = r\"/workspaces/rumour-detection-pheme/Dataset creation/posts_charlie_hebdo.pkl\"\n",
    "time_cut = 15\n",
    "\n",
    "processor = LoadRumoursDataset(file_path_replies, file_path_posts, time_cut)\n",
    "processor.load_data()\n",
    "processor.process_data()\n",
    "df_final = processor.get_final_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58b9d37a-6426-4f78-a1ec-706617e6f19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>followers</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>rumour</th>\n",
       "      <th>embeddings_avg</th>\n",
       "      <th>replies</th>\n",
       "      <th>first_time_diff</th>\n",
       "      <th>no_verified</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1628</td>\n",
       "      <td>14</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.12270056130364537, 0.01583862374536693, -0...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129573</td>\n",
       "      <td>38</td>\n",
       "      <td>486</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.12335950043052435, -0.055849663292368255, ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.783333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>529882</td>\n",
       "      <td>15</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.1364929385483265, -0.07159566258390744, -0...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.616667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>499741</td>\n",
       "      <td>15</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.045377860377941816, -0.20127306692302227, ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1377384</td>\n",
       "      <td>32</td>\n",
       "      <td>412</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.03706469060853124, -0.1309182441327721, -0...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>4881100</td>\n",
       "      <td>64</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.21622000262141228, -0.15450449846684933, -0...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>12942422</td>\n",
       "      <td>575</td>\n",
       "      <td>1368</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.21485890651291067, 0.03315381561829285, -0....</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>106530</td>\n",
       "      <td>234</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.08846200071275234, -0.1485882457345724, 0.1...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>4556025</td>\n",
       "      <td>143</td>\n",
       "      <td>437</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.021962551607025996, -0.019428667094972398, ...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>1261930</td>\n",
       "      <td>41</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.11712110787630081, -0.1469299958811866, -0....</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.050000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2002 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      followers  favorite_count  retweet_count  rumour  \\\n",
       "0          1628              14            159       1   \n",
       "1        129573              38            486       1   \n",
       "2        529882              15            127       1   \n",
       "3        499741              15            105       1   \n",
       "4       1377384              32            412       1   \n",
       "...         ...             ...            ...     ...   \n",
       "1997    4881100              64            167       0   \n",
       "1998   12942422             575           1368       0   \n",
       "1999     106530             234            410       0   \n",
       "2000    4556025             143            437       0   \n",
       "2001    1261930              41            133       0   \n",
       "\n",
       "                                         embeddings_avg  replies  \\\n",
       "0     [-0.12270056130364537, 0.01583862374536693, -0...      0.0   \n",
       "1     [-0.12335950043052435, -0.055849663292368255, ...      1.0   \n",
       "2     [-0.1364929385483265, -0.07159566258390744, -0...      2.0   \n",
       "3     [-0.045377860377941816, -0.20127306692302227, ...      3.0   \n",
       "4     [-0.03706469060853124, -0.1309182441327721, -0...      5.0   \n",
       "...                                                 ...      ...   \n",
       "1997  [0.21622000262141228, -0.15450449846684933, -0...      4.0   \n",
       "1998  [0.21485890651291067, 0.03315381561829285, -0....      9.0   \n",
       "1999  [0.08846200071275234, -0.1485882457345724, 0.1...      1.0   \n",
       "2000  [0.021962551607025996, -0.019428667094972398, ...     13.0   \n",
       "2001  [0.11712110787630081, -0.1469299958811866, -0....      4.0   \n",
       "\n",
       "      first_time_diff  no_verified  verified  \n",
       "0            0.000000            1         0  \n",
       "1            6.783333            0         1  \n",
       "2            5.616667            0         1  \n",
       "3            1.533333            0         1  \n",
       "4            0.683333            0         1  \n",
       "...               ...          ...       ...  \n",
       "1997         3.200000            0         1  \n",
       "1998         1.166667            0         1  \n",
       "1999         4.533333            1         0  \n",
       "2000         1.050000            0         1  \n",
       "2001         2.050000            0         1  \n",
       "\n",
       "[2002 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9863bea5-b581-4148-9a88-22916271258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usage\n",
    "file_path_replies = r\"/workspaces/rumour-detection-pheme/Dataset creation/replies_charlie_hebdo.pkl\"\n",
    "file_path_posts = r\"/workspaces/rumour-detection-pheme/Dataset creation/posts_charlie_hebdo.pkl\"\n",
    "time_cut = 15\n",
    "\n",
    "processor = HeteroDataProcessor(file_path_replies, file_path_posts, time_cut)\n",
    "data = processor.process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6905562-1d3d-4c07-8b19-e50255978fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user_id={\n",
       "    x=[2002, 106],\n",
       "    y=[2002],\n",
       "    train_mask=[2002],\n",
       "    val_mask=[2002],\n",
       "    test_mask=[2002],\n",
       "  },\n",
       "  reply_id={ x=[9559, 104] },\n",
       "  (user_id, retweet, reply_id)={ edge_index=[2, 9559] },\n",
       "  (reply_id, rev_retweet, user_id)={ edge_index=[2, 9559] }\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
