{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30b5ce4b-5497-48dc-9b54-612cf0b24f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80389a02-67c7-4da2-b2e1-0f6e52062402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the HeteroData object from the pkl file\n",
    "with open('charlie_hebdo_graph_dataset_node_embeddings_v2.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "864d7a06-2255-4b5e-b92c-342166d7a517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  id={\n",
       "    x=[2002, 106],\n",
       "    y=[2002],\n",
       "    train_mask=[2002],\n",
       "    val_mask=[2002],\n",
       "    test_mask=[2002],\n",
       "  },\n",
       "  reply_user_id={ x=[19050, 4] },\n",
       "  (id, retweet, reply_user_id)={ edge_index=[2, 19050] },\n",
       "  (reply_user_id, rev_retweet, id)={ edge_index=[2, 19050] }\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4034bcd-33e2-47da-8c99-d7e179bdd390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 | Train Loss: 0.7806 | Train Acc: 76.87% | Val Acc: 77.67%\n",
      "Epoch:  50 | Train Loss: 0.4272 | Train Acc: 80.51% | Val Acc: 84.00%\n",
      "Epoch: 100 | Train Loss: 0.3602 | Train Acc: 83.37% | Val Acc: 85.67%\n",
      "Epoch: 150 | Train Loss: 0.3304 | Train Acc: 85.51% | Val Acc: 86.33%\n",
      "Epoch: 200 | Train Loss: 0.3053 | Train Acc: 87.01% | Val Acc: 87.33%\n",
      "Epoch: 250 | Train Loss: 0.2615 | Train Acc: 88.29% | Val Acc: 87.67%\n",
      "Epoch: 300 | Train Loss: 0.2255 | Train Acc: 90.44% | Val Acc: 87.67%\n",
      "Epoch: 350 | Train Loss: 0.2012 | Train Acc: 92.93% | Val Acc: 87.67%\n",
      "Epoch: 400 | Train Loss: 0.1642 | Train Acc: 94.79% | Val Acc: 87.00%\n",
      "Epoch: 450 | Train Loss: 0.1347 | Train Acc: 96.65% | Val Acc: 87.00%\n",
      "Epoch: 500 | Train Loss: 0.1092 | Train Acc: 97.50% | Val Acc: 86.33%\n",
      "Epoch: 550 | Train Loss: 0.0859 | Train Acc: 98.29% | Val Acc: 86.33%\n",
      "Epoch: 600 | Train Loss: 0.0598 | Train Acc: 98.79% | Val Acc: 85.67%\n",
      "Epoch: 650 | Train Loss: 0.0596 | Train Acc: 99.21% | Val Acc: 86.67%\n",
      "Epoch: 700 | Train Loss: 0.0502 | Train Acc: 99.43% | Val Acc: 86.67%\n",
      "Epoch: 750 | Train Loss: 0.0489 | Train Acc: 99.64% | Val Acc: 87.00%\n",
      "Epoch: 800 | Train Loss: 0.0462 | Train Acc: 99.79% | Val Acc: 87.00%\n",
      "Epoch: 850 | Train Loss: 0.0237 | Train Acc: 99.71% | Val Acc: 87.33%\n",
      "Epoch: 900 | Train Loss: 0.0248 | Train Acc: 99.86% | Val Acc: 87.00%\n",
      "Epoch: 950 | Train Loss: 0.0215 | Train Acc: 99.79% | Val Acc: 86.67%\n",
      "Test accuracy: 87.71%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, to_hetero\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, dim_h, dim_out):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv((-1, -1), dim_h, add_self_loops=False)\n",
    "        self.conv2 = GATConv(dim_h, dim_h, add_self_loops=False)  # Added second GATConv layer\n",
    "        self.linear = nn.Linear(dim_h, dim_out)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index).relu()\n",
    "        h = self.dropout(h)\n",
    "        h = self.conv2(h, edge_index).relu()  # Pass through the second GATConv layer\n",
    "        h = self.dropout(h)\n",
    "        h = self.linear(h)\n",
    "        return h\n",
    "\n",
    "model = GAT(dim_h=64, dim_out=2)\n",
    "model = to_hetero(model, data.metadata(), aggr='sum')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data, model = data.to(device), model.to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(mask):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict)['id'].argmax(dim=-1)\n",
    "    acc = (pred[mask] == data['id'].y[mask]).sum() / mask.sum()\n",
    "    return float(acc)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)['id']\n",
    "    mask = data['id'].train_mask\n",
    "    loss = F.cross_entropy(out[mask], data['id'].y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        train_acc = test(data['id'].train_mask)\n",
    "        val_acc = test(data['id'].val_mask)\n",
    "        print(f'Epoch: {epoch:>3} | Train Loss: {loss:.4f} | Train Acc: {train_acc*100:.2f}% | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "test_acc = test(data['id'].test_mask)\n",
    "print(f'Test accuracy: {test_acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b3c75da-e447-42f3-b8ef-b8703b7d4e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8013392857142857"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mask = data['id'].test_mask\n",
    "pred = model(data.x_dict, data.edge_index_dict)['id'].argmax(dim=-1)\n",
    "true_labels = data['id'].y[test_mask]\n",
    "pred_labels = pred[test_mask]\n",
    "precision_score(true_labels, pred_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9acc72b-5da7-4f31-851f-d3383f2e3d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7939762443438914"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(true_labels, pred_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a024b12-7d50-4762-a7b1-ff5398f8e6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 | Train Loss: 0.6099 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:   5 | Train Loss: 0.5384 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  10 | Train Loss: 0.5333 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  15 | Train Loss: 0.5204 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  20 | Train Loss: 0.5275 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  25 | Train Loss: 0.5247 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  30 | Train Loss: 0.5239 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  35 | Train Loss: 0.5202 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  40 | Train Loss: 0.5196 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  45 | Train Loss: 0.5152 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  50 | Train Loss: 0.5224 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  55 | Train Loss: 0.5136 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  60 | Train Loss: 0.5124 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  65 | Train Loss: 0.5142 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  70 | Train Loss: 0.5128 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  75 | Train Loss: 0.5100 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  80 | Train Loss: 0.5092 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  85 | Train Loss: 0.5090 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  90 | Train Loss: 0.5120 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  95 | Train Loss: 0.5114 | Train Acc: 78.59% | Val Acc: 78.00%\n",
      "Test accuracy: 73.09%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, dim_h, dim_out):\n",
    "        super().__init__()\n",
    "        self.conv = GATConv((-1, -1), dim_h, add_self_loops=False)\n",
    "        self.linear = nn.Linear(dim_h, dim_out)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv(x, edge_index).relu()\n",
    "        h = self.dropout(h)\n",
    "        h = self.linear(h)\n",
    "        return h\n",
    "\n",
    "model = GAT(dim_h=64, dim_out=2)\n",
    "model = to_hetero(model, data.metadata(), aggr='sum')\n",
    "#print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data, model = data.to(device), model.to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(mask):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict)['id'].argmax(dim=-1)\n",
    "    true_labels = data['id'].y[mask]\n",
    "    pred_labels = pred[mask].cpu()\n",
    "    acc = (pred_labels == true_labels).sum() / mask.sum()\n",
    "    return float(acc)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)['id']\n",
    "    mask = data['id'].train_mask\n",
    "    loss = F.cross_entropy(out[mask], data['id'].y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        train_acc = test(data['id'].train_mask)\n",
    "        val_acc = test(data['id'].val_mask)\n",
    "        print(f'Epoch: {epoch:>3} | Train Loss: {loss:.4f} | Train Acc: {train_acc*100:.2f}% | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "test_acc = test(data['id'].test_mask)\n",
    "print(f'Test accuracy: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f78ae039-2f07-49da-a6b6-45bfeda0477c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36666666666666664"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(data.x_dict, data.edge_index_dict)['id'].argmax(dim=-1)\n",
    "true_labels = data['id'].y[test_mask]\n",
    "pred_labels = pred[test_mask]\n",
    "precision_score(true_labels, pred_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bd27037-fc13-4389-83cb-5d68994d2e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.497737556561086"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(true_labels, pred_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0838763-6598-4506-8ea4-b355caac52a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 | Train Loss: 5.2255 | Train Acc: 65.67% | Val Acc: 64.33%\n",
      "Epoch:  20 | Train Loss: 0.8749 | Train Acc: 77.44% | Val Acc: 78.00%\n",
      "Epoch:  40 | Train Loss: 0.5626 | Train Acc: 77.73% | Val Acc: 78.33%\n",
      "Epoch:  60 | Train Loss: 0.6310 | Train Acc: 76.30% | Val Acc: 76.67%\n",
      "Epoch:  80 | Train Loss: 0.5887 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch: 100 | Train Loss: 0.4921 | Train Acc: 77.94% | Val Acc: 77.67%\n",
      "Epoch: 120 | Train Loss: 1.0309 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch: 140 | Train Loss: 0.5430 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch: 160 | Train Loss: 0.4986 | Train Acc: 78.73% | Val Acc: 78.00%\n",
      "Epoch: 180 | Train Loss: 0.5077 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch: 200 | Train Loss: 0.4719 | Train Acc: 79.44% | Val Acc: 77.33%\n",
      "Epoch: 220 | Train Loss: 1.3693 | Train Acc: 81.51% | Val Acc: 79.00%\n",
      "Epoch: 240 | Train Loss: 0.4756 | Train Acc: 80.23% | Val Acc: 78.00%\n",
      "Epoch: 260 | Train Loss: 0.9111 | Train Acc: 80.37% | Val Acc: 77.67%\n",
      "Epoch: 280 | Train Loss: 0.6271 | Train Acc: 79.66% | Val Acc: 78.33%\n",
      "Epoch: 300 | Train Loss: 0.5259 | Train Acc: 79.73% | Val Acc: 78.00%\n",
      "Epoch: 320 | Train Loss: 0.4751 | Train Acc: 83.23% | Val Acc: 80.67%\n",
      "Epoch: 340 | Train Loss: 0.6067 | Train Acc: 80.51% | Val Acc: 78.67%\n",
      "Epoch: 360 | Train Loss: 0.4667 | Train Acc: 80.66% | Val Acc: 78.67%\n",
      "Epoch: 380 | Train Loss: 0.4398 | Train Acc: 80.30% | Val Acc: 79.00%\n",
      "Epoch: 400 | Train Loss: 0.4384 | Train Acc: 81.58% | Val Acc: 80.00%\n",
      "Epoch: 420 | Train Loss: 0.4633 | Train Acc: 81.23% | Val Acc: 79.33%\n",
      "Epoch: 440 | Train Loss: 0.9470 | Train Acc: 83.73% | Val Acc: 80.33%\n",
      "Epoch: 460 | Train Loss: 0.5075 | Train Acc: 80.09% | Val Acc: 78.67%\n",
      "Epoch: 480 | Train Loss: 0.4281 | Train Acc: 84.37% | Val Acc: 79.33%\n",
      "Test accuracy: 76.41%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import DBLP\n",
    "from torch_geometric.nn import HANConv, Linear\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class HAN(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, dim_h=64, heads=4):\n",
    "        super().__init__()\n",
    "        self.han = HANConv(dim_in, dim_h, heads=heads,dropout=0.5, metadata=data.metadata())\n",
    "        self.linear = nn.Linear(dim_h, dim_out)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        out = self.han(x_dict, edge_index_dict)\n",
    "        out = self.linear(out['id'])\n",
    "        return out\n",
    "\n",
    "model = HAN(dim_in=-1, dim_out=2)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data, model = data.to(device), model.to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(mask):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict).argmax(dim=-1)\n",
    "    acc = (pred[mask] == data['id'].y[mask]).sum() / mask.sum()\n",
    "    return float(acc)\n",
    "\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    mask = data['id'].train_mask\n",
    "    loss = F.cross_entropy(out[mask], data['id'].y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        train_acc = test(data['id'].train_mask)\n",
    "        val_acc = test(data['id'].val_mask)\n",
    "        print(f'Epoch: {epoch:>3} | Train Loss: {loss:.4f} | Train Acc: {train_acc*100:.2f}% | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "test_acc = test(data['id'].test_mask)\n",
    "print(f'Test accuracy: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a764403-e183-4099-a4b4-576cf445b68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7643951946975973"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred  =model(data.x_dict, data.edge_index_dict).argmax(dim=-1)\n",
    "true_labels = data['id'].y[test_mask]\n",
    "pred_labels = pred[test_mask]\n",
    "precision_score(true_labels, pred_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e959ec8d-83b1-4437-870a-de30147550d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5722002262443439"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(true_labels, pred_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5179b1d-efce-4d0a-9f68-ab79a205d01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 | Train Loss: 0.7408 | Train Acc: 74.02% | Val Acc: 73.67%\n",
      "Epoch:  20 | Train Loss: 0.5444 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  40 | Train Loss: 0.4293 | Train Acc: 78.52% | Val Acc: 78.00%\n",
      "Epoch:  60 | Train Loss: 0.3647 | Train Acc: 82.73% | Val Acc: 78.67%\n",
      "Epoch:  80 | Train Loss: 0.3197 | Train Acc: 85.44% | Val Acc: 79.67%\n",
      "Epoch: 100 | Train Loss: 0.2885 | Train Acc: 86.80% | Val Acc: 80.00%\n",
      "Epoch: 120 | Train Loss: 0.2759 | Train Acc: 88.51% | Val Acc: 80.67%\n",
      "Epoch: 140 | Train Loss: 0.2520 | Train Acc: 89.44% | Val Acc: 81.33%\n",
      "Epoch: 160 | Train Loss: 0.2344 | Train Acc: 90.79% | Val Acc: 82.67%\n",
      "Epoch: 180 | Train Loss: 0.2151 | Train Acc: 91.51% | Val Acc: 84.00%\n",
      "Epoch: 200 | Train Loss: 0.2003 | Train Acc: 91.93% | Val Acc: 83.33%\n",
      "Epoch: 220 | Train Loss: 0.1822 | Train Acc: 93.00% | Val Acc: 84.67%\n",
      "Epoch: 240 | Train Loss: 0.1616 | Train Acc: 93.72% | Val Acc: 84.33%\n",
      "Epoch: 260 | Train Loss: 0.1503 | Train Acc: 94.79% | Val Acc: 84.67%\n",
      "Epoch: 280 | Train Loss: 0.1410 | Train Acc: 96.22% | Val Acc: 85.00%\n",
      "Epoch: 300 | Train Loss: 0.1210 | Train Acc: 96.86% | Val Acc: 85.67%\n",
      "Epoch: 320 | Train Loss: 0.1050 | Train Acc: 97.72% | Val Acc: 85.33%\n",
      "Epoch: 340 | Train Loss: 0.0948 | Train Acc: 98.57% | Val Acc: 86.00%\n",
      "Epoch: 360 | Train Loss: 0.0776 | Train Acc: 98.64% | Val Acc: 85.67%\n",
      "Epoch: 380 | Train Loss: 0.0747 | Train Acc: 99.14% | Val Acc: 85.33%\n",
      "Epoch: 400 | Train Loss: 0.0734 | Train Acc: 99.36% | Val Acc: 85.67%\n",
      "Epoch: 420 | Train Loss: 0.0544 | Train Acc: 99.50% | Val Acc: 85.67%\n",
      "Epoch: 440 | Train Loss: 0.0564 | Train Acc: 99.43% | Val Acc: 85.00%\n",
      "Epoch: 460 | Train Loss: 0.0476 | Train Acc: 99.64% | Val Acc: 85.33%\n",
      "Epoch: 480 | Train Loss: 0.0426 | Train Acc: 99.57% | Val Acc: 85.67%\n",
      "Test accuracy: 83.06%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import DBLP\n",
    "from torch_geometric.nn import HANConv, Linear\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class HAN(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, dim_h=64, heads=4):\n",
    "        super().__init__()\n",
    "        self.han = HANConv(dim_in, dim_h, heads=heads,dropout=0.5, metadata=data.metadata())\n",
    "        self.han2 = HANConv(dim_h, dim_h, heads=heads, dropout=0.5, metadata=data.metadata())\n",
    "        self.linear = nn.Linear(dim_h, dim_out)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        out = self.han(x_dict, edge_index_dict)\n",
    "        out = self.han2(out, edge_index_dict)\n",
    "        out = self.linear(out['id'])\n",
    "        return out\n",
    "\n",
    "model = HAN(dim_in=-1, dim_out=2)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data, model = data.to(device), model.to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(mask):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict).argmax(dim=-1)\n",
    "    acc = (pred[mask] == data['id'].y[mask]).sum() / mask.sum()\n",
    "    return float(acc)\n",
    "\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    mask = data['id'].train_mask\n",
    "    loss = F.cross_entropy(out[mask], data['id'].y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        train_acc = test(data['id'].train_mask)\n",
    "        val_acc = test(data['id'].val_mask)\n",
    "        print(f'Epoch: {epoch:>3} | Train Loss: {loss:.4f} | Train Acc: {train_acc*100:.2f}% | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "test_acc = test(data['id'].test_mask)\n",
    "print(f'Test accuracy: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cf419f2-1f83-4144-a625-b71986174d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7832135933401756"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred  =model(data.x_dict, data.edge_index_dict).argmax(dim=-1)\n",
    "true_labels = data['id'].y[test_mask]\n",
    "pred_labels = pred[test_mask]\n",
    "precision_score(true_labels, pred_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "934b7a71-c382-4747-acff-a867c831f1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7809389140271493"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(true_labels, pred_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a64a2638-34d5-4613-bf5b-7b45814e8ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   Create_dataset_classes_with_time_cut.ipynb\u001b[m\n",
      "\t\u001b[31mmodified:   Graph Neural Networks.ipynb\u001b[m\n",
      "\t\u001b[31mmodified:   graph_dataset_creation.ipynb\u001b[m\n",
      "\t\u001b[31mmodified:   posts_charlie_hebdo.pkl\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31mcharlie_hebdo_graph_dataset_node_embeddings_v2.pkl\u001b[m\n",
      "\t\u001b[31mreplies_charlie_hebdo.pkl\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "! git commit -m \"commit 06-08\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebfc9f52-aa06-49b6-986d-2d7b0ce08e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything up-to-date\n"
     ]
    }
   ],
   "source": [
    "!git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
