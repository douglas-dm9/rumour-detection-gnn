{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30b5ce4b-5497-48dc-9b54-612cf0b24f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80389a02-67c7-4da2-b2e1-0f6e52062402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the HeteroData object from the pkl file\n",
    "with open('charlie_hebdo_graph_dataset_reply_node_embeddings.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "864d7a06-2255-4b5e-b92c-342166d7a517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user_id={\n",
       "    x=[2002, 106],\n",
       "    y=[2002],\n",
       "    train_mask=[2002],\n",
       "    val_mask=[2002],\n",
       "    test_mask=[2002],\n",
       "  },\n",
       "  reply_id={ x=[19050, 104] },\n",
       "  (user_id, retweet, reply_id)={ edge_index=[2, 19050] },\n",
       "  (reply_id, rev_retweet, user_id)={ edge_index=[2, 19050] }\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4034bcd-33e2-47da-8c99-d7e179bdd390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 | Train Loss: 0.7665 | Train Acc: 23.70% | Val Acc: 27.33%\n",
      "Epoch:   5 | Train Loss: 0.7085 | Train Acc: 33.76% | Val Acc: 35.67%\n",
      "Epoch:  10 | Train Loss: 0.6862 | Train Acc: 88.94% | Val Acc: 87.00%\n",
      "Epoch:  15 | Train Loss: 0.6583 | Train Acc: 89.65% | Val Acc: 90.00%\n",
      "Epoch:  20 | Train Loss: 0.6465 | Train Acc: 89.79% | Val Acc: 90.67%\n",
      "Epoch:  25 | Train Loss: 0.6148 | Train Acc: 89.79% | Val Acc: 91.67%\n",
      "Epoch:  30 | Train Loss: 0.5942 | Train Acc: 90.15% | Val Acc: 91.67%\n",
      "Epoch:  35 | Train Loss: 0.5934 | Train Acc: 90.51% | Val Acc: 91.00%\n",
      "Epoch:  40 | Train Loss: 0.5471 | Train Acc: 90.72% | Val Acc: 91.33%\n",
      "Epoch:  45 | Train Loss: 0.5332 | Train Acc: 91.01% | Val Acc: 91.67%\n",
      "Epoch:  50 | Train Loss: 0.5423 | Train Acc: 91.29% | Val Acc: 92.33%\n",
      "Epoch:  55 | Train Loss: 0.5090 | Train Acc: 91.79% | Val Acc: 93.00%\n",
      "Epoch:  60 | Train Loss: 0.4890 | Train Acc: 91.79% | Val Acc: 93.33%\n",
      "Epoch:  65 | Train Loss: 0.4655 | Train Acc: 92.36% | Val Acc: 93.33%\n",
      "Epoch:  70 | Train Loss: 0.4826 | Train Acc: 92.51% | Val Acc: 93.67%\n",
      "Epoch:  75 | Train Loss: 0.4357 | Train Acc: 92.93% | Val Acc: 94.67%\n",
      "Epoch:  80 | Train Loss: 0.4175 | Train Acc: 93.29% | Val Acc: 94.67%\n",
      "Epoch:  85 | Train Loss: 0.4116 | Train Acc: 93.50% | Val Acc: 94.67%\n",
      "Epoch:  90 | Train Loss: 0.4258 | Train Acc: 93.50% | Val Acc: 94.67%\n",
      "Epoch:  95 | Train Loss: 0.3778 | Train Acc: 93.58% | Val Acc: 95.00%\n",
      "Test accuracy: 95.35%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, to_hetero\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, dim_h, dim_out):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv((-1, -1), dim_h, add_self_loops=False)\n",
    "        self.conv2 = GATConv(dim_h, dim_h, add_self_loops=False)  # Added second GATConv layer\n",
    "        self.linear = nn.Linear(dim_h, dim_out)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index).relu()\n",
    "        h = self.dropout(h)\n",
    "        h = self.conv2(h, edge_index).relu()  # Pass through the second GATConv layer\n",
    "        h = self.dropout(h)\n",
    "        h = self.linear(h)\n",
    "        return h\n",
    "\n",
    "model = GAT(dim_h=64, dim_out=2)\n",
    "model = to_hetero(model, data.metadata(), aggr='sum')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data, model = data.to(device), model.to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(mask):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict)['user_id'].argmax(dim=-1)\n",
    "    acc = (pred[mask] == data['user_id'].y[mask]).sum() / mask.sum()\n",
    "    return float(acc)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)['user_id']\n",
    "    mask = data['user_id'].train_mask\n",
    "    loss = F.cross_entropy(out[mask], data['user_id'].y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        train_acc = test(data['user_id'].train_mask)\n",
    "        val_acc = test(data['user_id'].val_mask)\n",
    "        print(f'Epoch: {epoch:>3} | Train Loss: {loss:.4f} | Train Acc: {train_acc*100:.2f}% | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "test_acc = test(data['user_id'].test_mask)\n",
    "print(f'Test accuracy: {test_acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b3c75da-e447-42f3-b8ef-b8703b7d4e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9274779946421737"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mask = data['user_id'].test_mask\n",
    "pred = model(data.x_dict, data.edge_index_dict)['user_id'].argmax(dim=-1)\n",
    "true_labels = data['user_id'].y[test_mask]\n",
    "pred_labels = pred[test_mask]\n",
    "precision_score(true_labels, pred_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9acc72b-5da7-4f31-851f-d3383f2e3d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936897001303781"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(true_labels, pred_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a024b12-7d50-4762-a7b1-ff5398f8e6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 | Train Loss: 0.8510 | Train Acc: 27.41% | Val Acc: 28.00%\n",
      "Epoch:   5 | Train Loss: 0.6648 | Train Acc: 82.51% | Val Acc: 78.67%\n",
      "Epoch:  10 | Train Loss: 0.5663 | Train Acc: 84.58% | Val Acc: 82.67%\n",
      "Epoch:  15 | Train Loss: 0.4597 | Train Acc: 84.87% | Val Acc: 83.33%\n",
      "Epoch:  20 | Train Loss: 0.3765 | Train Acc: 86.22% | Val Acc: 84.00%\n",
      "Epoch:  25 | Train Loss: 0.3197 | Train Acc: 87.22% | Val Acc: 84.00%\n",
      "Epoch:  30 | Train Loss: 0.2930 | Train Acc: 88.08% | Val Acc: 83.33%\n",
      "Epoch:  35 | Train Loss: 0.2690 | Train Acc: 89.01% | Val Acc: 83.67%\n",
      "Epoch:  40 | Train Loss: 0.2423 | Train Acc: 89.58% | Val Acc: 83.67%\n",
      "Epoch:  45 | Train Loss: 0.2317 | Train Acc: 90.29% | Val Acc: 83.67%\n",
      "Epoch:  50 | Train Loss: 0.2350 | Train Acc: 90.51% | Val Acc: 84.33%\n",
      "Epoch:  55 | Train Loss: 0.2129 | Train Acc: 91.08% | Val Acc: 84.67%\n",
      "Epoch:  60 | Train Loss: 0.2027 | Train Acc: 91.65% | Val Acc: 84.67%\n",
      "Epoch:  65 | Train Loss: 0.1975 | Train Acc: 92.08% | Val Acc: 83.67%\n",
      "Epoch:  70 | Train Loss: 0.1802 | Train Acc: 92.79% | Val Acc: 83.67%\n",
      "Epoch:  75 | Train Loss: 0.1771 | Train Acc: 93.36% | Val Acc: 85.00%\n",
      "Epoch:  80 | Train Loss: 0.1628 | Train Acc: 93.79% | Val Acc: 84.33%\n",
      "Epoch:  85 | Train Loss: 0.1582 | Train Acc: 94.65% | Val Acc: 83.33%\n",
      "Epoch:  90 | Train Loss: 0.1550 | Train Acc: 94.22% | Val Acc: 84.00%\n",
      "Epoch:  95 | Train Loss: 0.1504 | Train Acc: 94.86% | Val Acc: 84.67%\n",
      "Test accuracy: 79.07%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, dim_h, dim_out):\n",
    "        super().__init__()\n",
    "        self.conv = GATConv((-1, -1), dim_h, add_self_loops=False)\n",
    "        self.linear = nn.Linear(dim_h, dim_out)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv(x, edge_index).relu()\n",
    "        h = self.dropout(h)\n",
    "        h = self.linear(h)\n",
    "        return h\n",
    "\n",
    "model = GAT(dim_h=64, dim_out=2)\n",
    "model = to_hetero(model, data.metadata(), aggr='sum')\n",
    "#print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data, model = data.to(device), model.to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(mask):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict)['user_id'].argmax(dim=-1)\n",
    "    true_labels = data['user_id'].y[mask]\n",
    "    pred_labels = pred[mask].cpu()\n",
    "    acc = (pred_labels == true_labels).sum() / mask.sum()\n",
    "    return float(acc)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)['user_id']\n",
    "    mask = data['user_id'].train_mask\n",
    "    loss = F.cross_entropy(out[mask], data['user_id'].y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        train_acc = test(data['user_id'].train_mask)\n",
    "        val_acc = test(data['user_id'].val_mask)\n",
    "        print(f'Epoch: {epoch:>3} | Train Loss: {loss:.4f} | Train Acc: {train_acc*100:.2f}% | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "test_acc = test(data['user_id'].test_mask)\n",
    "print(f'Test accuracy: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f78ae039-2f07-49da-a6b6-45bfeda0477c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6890268592252666"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(data.x_dict, data.edge_index_dict)['user_id'].argmax(dim=-1)\n",
    "true_labels = data['user_id'].y[test_mask]\n",
    "pred_labels = pred[test_mask]\n",
    "precision_score(true_labels, pred_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bd27037-fc13-4389-83cb-5d68994d2e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6825945241199478"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(true_labels, pred_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0838763-6598-4506-8ea4-b355caac52a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 | Train Loss: 0.7825 | Train Acc: 27.48% | Val Acc: 28.00%\n",
      "Epoch:  20 | Train Loss: 0.5739 | Train Acc: 86.65% | Val Acc: 83.33%\n",
      "Epoch:  40 | Train Loss: 0.4147 | Train Acc: 93.29% | Val Acc: 88.00%\n",
      "Epoch:  60 | Train Loss: 0.3042 | Train Acc: 95.86% | Val Acc: 90.00%\n",
      "Epoch:  80 | Train Loss: 0.2408 | Train Acc: 97.36% | Val Acc: 89.33%\n",
      "Epoch: 100 | Train Loss: 0.2083 | Train Acc: 98.64% | Val Acc: 88.67%\n",
      "Epoch: 120 | Train Loss: 0.1580 | Train Acc: 99.29% | Val Acc: 88.33%\n",
      "Epoch: 140 | Train Loss: 0.1421 | Train Acc: 99.50% | Val Acc: 87.33%\n",
      "Epoch: 160 | Train Loss: 0.1188 | Train Acc: 99.71% | Val Acc: 88.00%\n",
      "Epoch: 180 | Train Loss: 0.1113 | Train Acc: 99.86% | Val Acc: 88.67%\n",
      "Epoch: 200 | Train Loss: 0.0904 | Train Acc: 99.86% | Val Acc: 87.67%\n",
      "Epoch: 220 | Train Loss: 0.0786 | Train Acc: 99.93% | Val Acc: 88.33%\n",
      "Epoch: 240 | Train Loss: 0.0836 | Train Acc: 99.93% | Val Acc: 88.67%\n",
      "Epoch: 260 | Train Loss: 0.0700 | Train Acc: 99.93% | Val Acc: 87.67%\n",
      "Epoch: 280 | Train Loss: 0.0631 | Train Acc: 99.93% | Val Acc: 87.67%\n",
      "Epoch: 300 | Train Loss: 0.0642 | Train Acc: 99.93% | Val Acc: 87.33%\n",
      "Epoch: 320 | Train Loss: 0.0580 | Train Acc: 99.93% | Val Acc: 87.33%\n",
      "Epoch: 340 | Train Loss: 0.0492 | Train Acc: 99.93% | Val Acc: 89.00%\n",
      "Epoch: 360 | Train Loss: 0.0405 | Train Acc: 99.93% | Val Acc: 88.00%\n",
      "Epoch: 380 | Train Loss: 0.0553 | Train Acc: 99.93% | Val Acc: 87.33%\n",
      "Epoch: 400 | Train Loss: 0.0459 | Train Acc: 99.93% | Val Acc: 89.33%\n",
      "Epoch: 420 | Train Loss: 0.0362 | Train Acc: 99.93% | Val Acc: 87.33%\n",
      "Epoch: 440 | Train Loss: 0.0424 | Train Acc: 99.93% | Val Acc: 87.33%\n",
      "Epoch: 460 | Train Loss: 0.0444 | Train Acc: 99.93% | Val Acc: 87.67%\n",
      "Epoch: 480 | Train Loss: 0.0346 | Train Acc: 99.93% | Val Acc: 87.33%\n",
      "Test accuracy: 88.37%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import DBLP\n",
    "from torch_geometric.nn import HANConv, Linear\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class HAN(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, dim_h=64, heads=4):\n",
    "        super().__init__()\n",
    "        self.han = HANConv(dim_in, dim_h, heads=heads,dropout=0.5, metadata=data.metadata())\n",
    "        self.linear = nn.Linear(dim_h, dim_out)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        out = self.han(x_dict, edge_index_dict)\n",
    "        out = self.linear(out['user_id'])\n",
    "        return out\n",
    "\n",
    "model = HAN(dim_in=-1, dim_out=2)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data, model = data.to(device), model.to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(mask):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict).argmax(dim=-1)\n",
    "    acc = (pred[mask] == data['user_id'].y[mask]).sum() / mask.sum()\n",
    "    return float(acc)\n",
    "\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    mask = data['user_id'].train_mask\n",
    "    loss = F.cross_entropy(out[mask], data['user_id'].y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        train_acc = test(data['user_id'].train_mask)\n",
    "        val_acc = test(data['user_id'].val_mask)\n",
    "        print(f'Epoch: {epoch:>3} | Train Loss: {loss:.4f} | Train Acc: {train_acc*100:.2f}% | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "test_acc = test(data['user_id'].test_mask)\n",
    "print(f'Test accuracy: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a764403-e183-4099-a4b4-576cf445b68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8220175438596491"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred  =model(data.x_dict, data.edge_index_dict).argmax(dim=-1)\n",
    "true_labels = data['user_id'].y[test_mask]\n",
    "pred_labels = pred[test_mask]\n",
    "precision_score(true_labels, pred_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e959ec8d-83b1-4437-870a-de30147550d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8589634941329857"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(true_labels, pred_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5179b1d-efce-4d0a-9f68-ab79a205d01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 | Train Loss: 0.6881 | Train Acc: 83.51% | Val Acc: 81.67%\n",
      "Epoch:  20 | Train Loss: 0.6121 | Train Acc: 90.22% | Val Acc: 91.67%\n",
      "Epoch:  40 | Train Loss: 0.5350 | Train Acc: 92.22% | Val Acc: 92.33%\n",
      "Epoch:  60 | Train Loss: 0.4833 | Train Acc: 93.29% | Val Acc: 94.00%\n",
      "Epoch:  80 | Train Loss: 0.4609 | Train Acc: 94.15% | Val Acc: 94.00%\n",
      "Epoch: 100 | Train Loss: 0.4339 | Train Acc: 95.29% | Val Acc: 95.33%\n",
      "Epoch: 120 | Train Loss: 0.4051 | Train Acc: 96.07% | Val Acc: 95.00%\n",
      "Epoch: 140 | Train Loss: 0.3738 | Train Acc: 96.57% | Val Acc: 95.67%\n",
      "Epoch: 160 | Train Loss: 0.3653 | Train Acc: 97.29% | Val Acc: 94.33%\n",
      "Epoch: 180 | Train Loss: 0.3405 | Train Acc: 97.86% | Val Acc: 94.33%\n",
      "Epoch: 200 | Train Loss: 0.3150 | Train Acc: 98.72% | Val Acc: 95.33%\n",
      "Epoch: 220 | Train Loss: 0.2973 | Train Acc: 98.79% | Val Acc: 95.67%\n",
      "Epoch: 240 | Train Loss: 0.2901 | Train Acc: 99.14% | Val Acc: 94.67%\n",
      "Epoch: 260 | Train Loss: 0.2757 | Train Acc: 99.36% | Val Acc: 95.33%\n",
      "Epoch: 280 | Train Loss: 0.2600 | Train Acc: 99.79% | Val Acc: 94.33%\n",
      "Epoch: 300 | Train Loss: 0.2556 | Train Acc: 99.79% | Val Acc: 94.67%\n",
      "Epoch: 320 | Train Loss: 0.2426 | Train Acc: 99.86% | Val Acc: 95.67%\n",
      "Epoch: 340 | Train Loss: 0.2336 | Train Acc: 99.93% | Val Acc: 95.00%\n",
      "Epoch: 360 | Train Loss: 0.2284 | Train Acc: 99.93% | Val Acc: 95.33%\n",
      "Epoch: 380 | Train Loss: 0.2202 | Train Acc: 99.93% | Val Acc: 95.00%\n",
      "Epoch: 400 | Train Loss: 0.2152 | Train Acc: 99.93% | Val Acc: 95.00%\n",
      "Epoch: 420 | Train Loss: 0.2045 | Train Acc: 99.93% | Val Acc: 95.00%\n",
      "Epoch: 440 | Train Loss: 0.2012 | Train Acc: 99.93% | Val Acc: 95.33%\n",
      "Epoch: 460 | Train Loss: 0.1952 | Train Acc: 99.93% | Val Acc: 94.00%\n",
      "Epoch: 480 | Train Loss: 0.1848 | Train Acc: 99.93% | Val Acc: 95.67%\n",
      "Test accuracy: 95.35%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import DBLP\n",
    "from torch_geometric.nn import HANConv, Linear\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class HAN(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, dim_h=64, heads=4):\n",
    "        super().__init__()\n",
    "        self.han = HANConv(dim_in, dim_h, heads=heads,dropout=0.5, metadata=data.metadata())\n",
    "        self.han2 = HANConv(dim_h, dim_h, heads=heads, dropout=0.5, metadata=data.metadata())\n",
    "        self.linear = nn.Linear(dim_h, dim_out)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        out = self.han(x_dict, edge_index_dict)\n",
    "        out = self.han2(out, edge_index_dict)\n",
    "        out = self.linear(out['user_id'])\n",
    "        return out\n",
    "\n",
    "model = HAN(dim_in=-1, dim_out=2)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data, model = data.to(device), model.to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(mask):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict).argmax(dim=-1)\n",
    "    acc = (pred[mask] == data['user_id'].y[mask]).sum() / mask.sum()\n",
    "    return float(acc)\n",
    "\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    mask = data['user_id'].train_mask\n",
    "    loss = F.cross_entropy(out[mask], data['user_id'].y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        train_acc = test(data['user_id'].train_mask)\n",
    "        val_acc = test(data['user_id'].val_mask)\n",
    "        print(f'Epoch: {epoch:>3} | Train Loss: {loss:.4f} | Train Acc: {train_acc*100:.2f}% | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "test_acc = test(data['user_id'].test_mask)\n",
    "print(f'Test accuracy: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cf419f2-1f83-4144-a625-b71986174d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9313233376792699"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred  =model(data.x_dict, data.edge_index_dict).argmax(dim=-1)\n",
    "true_labels = data['user_id'].y[test_mask]\n",
    "pred_labels = pred[test_mask]\n",
    "precision_score(true_labels, pred_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "934b7a71-c382-4747-acff-a867c831f1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9313233376792699"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(true_labels, pred_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a64a2638-34d5-4613-bf5b-7b45814e8ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 64e6c49] commit 30-06\n",
      " 9 files changed, 4605 insertions(+), 6000 deletions(-)\n",
      " create mode 100644 Dataset creation/.ipynb_checkpoints/Graph Neural Networks-checkpoint.ipynb\n",
      " rename Dataset creation/.ipynb_checkpoints/{Charlie_hebdo_v1-checkpoint.ipynb => eda-checkpoint.ipynb} (99%)\n",
      " create mode 100644 Dataset creation/Graph Neural Networks.ipynb\n",
      " create mode 100644 Dataset creation/charlie_hebdo_graph_dataset_node_embeddings.pkl\n",
      " rename Dataset creation/{charlie_hebdo_graph_dataset.pkl => charlie_hebdo_graph_dataset_reply_node_embeddings.pkl} (59%)\n",
      " rename Dataset creation/{Charlie_hebdo_v1.ipynb => eda.ipynb} (94%)\n"
     ]
    }
   ],
   "source": [
    "! git commit -m \"commit 30-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfc9f52-aa06-49b6-986d-2d7b0ce08e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 41, done.\n",
      "Counting objects: 100% (41/41), done.\n",
      "Delta compression using up to 2 threads\n",
      "Compressing objects: 100% (35/35), done.\n",
      "error: RPC failed; HTTP 400 curl 22 The requested URL returned error: 400\n",
      "send-pack: unexpected disconnect while reading sideband packet\n",
      "Writing objects:  45% (18/40), 103.07 MiB | 3.64 MiB/s \r"
     ]
    }
   ],
   "source": [
    "!git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
